# =============================================================================
# LLM Configuration (Required)
# =============================================================================

# vLLM model to serve (REQUIRED - no default)
# Examples:
#   MODEL=mistralai/Mistral-7B-Instruct-v0.3
#   MODEL=meta-llama/Llama-3.1-8B-Instruct
#   MODEL=Qwen/Qwen2.5-7B-Instruct
MODEL=

# HuggingFace token (required for gated models like Llama)
# Get your token at: https://huggingface.co/settings/tokens
HF_TOKEN=

# =============================================================================
# vLLM Configuration
# =============================================================================

# vLLM API endpoint (OpenAI-compatible)
VLLM_BASE_URL=http://vllm:8000/v1

# Model name for vLLM (defaults to MODEL if not set)
# VLLM_MODEL_NAME=${MODEL}

# Maximum tokens for LLM response (default: 1024)
# Reduce if you get "max_tokens is too large" errors with long inputs
LLM_MAX_TOKENS=1024

# LLM temperature (0.0-1.0, default: 0.7)
LLM_TEMPERATURE=0.7

# =============================================================================
# Embedding Configuration
# =============================================================================

# Local embedding model (runs via @huggingface/transformers)
# Default: Xenova/all-MiniLM-L6-v2 (384 dimensions, fast, good quality)
# Alternatives: Xenova/bge-small-en-v1.5, Xenova/gte-small
EMBEDDING_MODEL=Xenova/all-MiniLM-L6-v2

# =============================================================================
# Agent Configuration
# =============================================================================

# Maximum number of recent messages to include in context
AGENT_MAX_CONTEXT_MESSAGES=20

# Minimum similarity score for document retrieval (0.0 - 1.0)
AGENT_SIMILARITY_THRESHOLD=0.7

# =============================================================================
# Database Configuration
# =============================================================================

POSTGRES_USER=agent
POSTGRES_PASSWORD=changeme
POSTGRES_DB=agent_db

# =============================================================================
# Grafana Configuration
# =============================================================================

GRAFANA_ADMIN_PASSWORD=admin

# =============================================================================
# Security Configuration
# =============================================================================

# VirusTotal API key for file scanning (optional - scanning skipped if not set)
# Get your API key at: https://www.virustotal.com/gui/my-apikey
VIRUSTOTAL_API_KEY=

# =============================================================================
# Document Processing Configuration
# =============================================================================

# TTL in hours for temporary documents attached to chat (default: 24)
DOCUMENT_TTL_HOURS=24

# PDF chunk size for text splitting (default: 1000)
PDF_CHUNK_SIZE=1000

# PDF chunk overlap for text splitting (default: 200)
PDF_CHUNK_OVERLAP=200

# =============================================================================
# Logging Configuration
# =============================================================================

# Log level: error, warn, info, debug, verbose
LOG_LEVEL=info

# Directory for log files (relative to app root)
LOG_DIR=logs

# Enable/disable database logging (true/false)
LOG_TO_DB=true

# Retention period for database logs in days
LOG_RETENTION_DAYS=30

# =============================================================================
# Health Check Configuration
# =============================================================================

# Timeout for vLLM health check in milliseconds
VLLM_HEALTH_TIMEOUT=5000

# =============================================================================
# Application Configuration (Optional)
# =============================================================================

# PORT=3000
# NODE_ENV=production
